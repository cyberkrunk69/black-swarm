[
  {
    "task": "FEEDBACK LOOP: Critic Retry Integration\n\nWire critic.py into grind_spawner's execution loop:\n\n1. Read grind_spawner.py and critic.py\n2. After worker completes, call critic.review() on output\n3. If quality_score < 0.7, inject feedback and retry (max 2 retries)\n4. Log quality scores to performance_tracker\n\nEdit grind_spawner.py to add retry logic after task completion.",
    "budget": 0.80,
    "model": "sonnet"
  },
  {
    "task": "PERSISTENCE: DSPy Demonstration Storage\n\nAdd demonstration persistence to prompt_optimizer.py:\n\n1. Read prompt_optimizer.py\n2. Add save_demonstrations(filepath='demos.json') method\n3. Add load_demonstrations(filepath='demos.json') method\n4. Auto-save after collecting new demos\n5. Auto-load at startup if file exists\n\nUse JSON format. Ensure demos persist across sessions.",
    "budget": 0.80,
    "model": "sonnet"
  },
  {
    "task": "INTEGRATION: Performance to Improvement Loop\n\nWire performance_tracker.py to improvement_suggester.py:\n\n1. Read both files to understand their interfaces\n2. Create connect_tracker_to_suggester() function\n3. After each wave, call suggester with tracker data\n4. Save suggestions to improvement_reports/ directory\n5. Feed top suggestion into next wave planning\n\nEdit grind_spawner.py to add post-wave analysis.",
    "budget": 0.80,
    "model": "sonnet"
  },
  {
    "task": "EMBEDDINGS: Semantic Skill Retrieval\n\nAdd embedding-based retrieval to skill_registry.py:\n\n1. Read skills/skill_registry.py\n2. Add compute_embedding(text) using TF-IDF vectorization\n3. Add find_similar_skills(query, top_k=3) method\n4. Replace keyword matching with cosine similarity\n5. Cache embeddings for performance\n\nUse sklearn TfidfVectorizer if available, else simple hash.",
    "budget": 0.80,
    "model": "sonnet"
  },
  {
    "task": "KNOWLEDGE GRAPH: Wire to Main Flow\n\nIntegrate knowledge_graph.py into grind_spawner.py:\n\n1. Read both files\n2. Load/initialize KG at GrindSession startup\n3. Call kg.populate_from_codebase() once per session\n4. In prompt building, inject kg.get_related_concepts(task) context\n5. Save KG state to knowledge_graph.json after session\n\nMake KG context available for better task understanding.",
    "budget": 0.80,
    "model": "sonnet"
  },
  {
    "task": "KNOWLEDGE GRAPH: Lesson Auto-Population\n\nExtend knowledge_graph.py to capture session learnings:\n\n1. Read knowledge_graph.py\n2. Add add_lesson_node(lesson_dict) method\n3. Add link_lesson_to_concepts(lesson_id, concepts) method\n4. Call after each successful task in grind_spawner\n5. Extract concepts from lesson text automatically\n\nKG should grow with each session.",
    "budget": 0.80,
    "model": "sonnet"
  },
  {
    "task": "TREE SEARCH: Real Expansion Implementation\n\nFix tree_search.py expand_node() to generate actual branches:\n\n1. Read tree_search.py\n2. In expand_node(), generate 2-3 alternative approaches\n3. Each child node has different strategy/prompt variation\n4. Use heuristics based on task type (refactor vs implement vs fix)\n5. Return list of valid child TreeNodes\n\nReplace TODO stubs with real logic.",
    "budget": 0.80,
    "model": "sonnet"
  },
  {
    "task": "TREE SEARCH: Real Evaluation Implementation\n\nFix tree_search.py evaluate_node() to score solutions:\n\n1. Read tree_search.py and critic.py\n2. In evaluate_node(), call critic.review() on node output\n3. Return quality_score as evaluation (0.0-1.0)\n4. Cache evaluations to avoid re-computation\n5. Handle nodes without output gracefully\n\nWire tree search to critic for scoring.",
    "budget": 0.80,
    "model": "sonnet"
  },
  {
    "task": "ONLINE LEARNING: Session Feedback Capture\n\nAdd real-time learning to grind_spawner.py:\n\n1. Read grind_spawner.py\n2. After each task, extract what worked/failed\n3. Update prompt_optimizer with new demonstration\n4. Update skill_registry if new pattern found\n5. Log learning events to learning_log.json\n\nAI should improve during session, not just after.",
    "budget": 0.80,
    "model": "sonnet"
  },
  {
    "task": "INTEGRATION TESTS: Feedback Loop Validation\n\nAdd tests for the new feedback loops:\n\n1. Create tests/test_feedback_loops.py\n2. Test critic retry triggers on low quality\n3. Test DSPy demos persist and load\n4. Test performance->suggester pipeline\n5. Test KG population from lessons\n\nEnsure all feedback loops actually work end-to-end.",
    "budget": 0.80,
    "model": "sonnet"
  }
]
