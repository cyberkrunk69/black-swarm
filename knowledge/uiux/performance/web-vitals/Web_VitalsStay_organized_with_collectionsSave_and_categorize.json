{
  "id": "web-vitals__articles_vitals",
  "source_id": "web-vitals",
  "source_name": "Web Vitals",
  "category": "performance",
  "url": "https://web.dev/articles/vitals",
  "title": "Web VitalsStay organized with collectionsSave and categorize content based on your preferences.",
  "content": "Home\nArticles\nWeb Vitals\nStay organized with collections\nSave and categorize content based on your preferences.\nPhilip Walton\nPublished: May 4, 2020\nOptimizing for quality of user experience is key to the long-term success of any site on the web. Whether you're a business owner, marketer, or developer, Web Vitals can help you quantify the experience of your site and identify opportunities to improve.\nOverview\nWeb Vitals is an initiative by Google to provide unified guidance for quality signals that are essential to delivering a great user experience on the web.\nGoogle has provided a number of tools over the years to measure and report on performance. Some developers are experts at using these tools, while others have found the abundance of both tools and metrics challenging to keep up with.\nSite owners shouldn't have to be performance experts to understand the quality of experience they are delivering to their users. The Web Vitals initiative aims to simplify the landscape, and help sites focus on the metrics that matter most, the\nCore Web Vitals\n.\nCore Web Vitals\nCore Web Vitals are the subset of Web Vitals that apply to all web pages, should be measured by all site owners, and will be surfaced across all Google tools. Each of the Core Web Vitals represents a distinct facet of the user experience, is measurable\nin the field\n, and reflects the real-world experience of a critical\nuser-centric\noutcome.\nThe metrics that make up Core Web Vitals will\nevolve\nover time. The current set focuses on three aspects of the user experience\u2014\nloading\n,\ninteractivity\n, and\nvisual stability\n\u2014and includes the following metrics (and their respective thresholds):\nLargest Contentful Paint (LCP)\n: measures\nloading\nperformance. To provide a good user experience, LCP should occur within\n2.5 seconds\nof when the page first starts loading.\nInteraction to Next Paint (INP)\n: measures\ninteractivity\n. To provide a good user experience, pages should have a INP of\n200 milliseconds\nor less.\nCumulative Layout Shift (CLS)\n: measures\nvisual stability\n. To provide a good user experience, pages should maintain a CLS of\n0.1.\nor less.\nTo ensure you're hitting the recommended target for these metrics for most of your users, a good threshold to measure is the\n75th percentile\nof page loads, segmented across mobile and desktop devices.\nTools that assess Core Web Vitals compliance should consider a page passing if it meets the recommended targets at the 75th percentile for all three of the Core Web Vitals metrics.\nLifecycle\nMetrics on the Core Web Vitals track go through a lifecycle consisting of three phases: experimental, pending, and stable.\nThe stages of the Core Web Vitals lifecycle.\nEach phase is designed to signal to developers how they should think about each metric:\nExperimental metrics\nare prospective Core Web Vitals that may still be undergoing significant changes depending on testing and community feedback.\nPending metrics\nare future Core Web Vitals that have passed the testing and feedback stage and have a well-defined timeline to becoming stable.\nStable metrics\nare the current set of Core Web Vitals that Chrome considers essential for great user experiences.\nThe Core Web Vitals are at the following lifecycle stages:\nLCP\n: Stable\nCLS\n: Stable\nINP\n: Stable\nExperimental\nWhen a metric is initially developed and enters the ecosystem, it is considered an\nexperimental metric\n.\nThe purpose of the experimental phase is to assess a metric's fitness, first by exploring the problem to be solved, and possibly iterate on what previous metrics may have failed to address. For example,\nInteraction to Next Paint (INP)\nwas initially developed as an experimental metric to address the runtime performance issues present on the web more comprehensively than\nFirst Input Delay (FID)\n.\nThe experimental phase of Core Web Vitals lifecycle is also intended to give flexibility in a metric's development by identifying bugs and even exploring changes to its initial definition. It's also the phase in which community feedback is most important.\nPending\nWhen the Chrome team determines that an experimental metric has received sufficient feedback and proven its efficacy, it becomes a\npending metric\n. For example, INP was promoted in 2023 from experimental to pending status with the intent to eventually retire FID.\nPending metrics are held in this phase for a minimum of six months to give the ecosystem time to adapt. Community feedback remains an important aspect of this phase, as more developers begin to use the metric.\nStable\nWhen a Core Web Vital candidate metric is finalized, it becomes a\nstable metric\n. This is when the metric can become a Core Web Vital.\nStable metrics are actively supported, and can be subject to bug fixes and definition changes. Stable Core Web Vitals metrics won't change more than once per year. Any change to a Core Web Vital will be clearly communicated in the metric's official documentation, as well as in the metric's changelog. Core Web Vitals are also included in any assessments.\nTools to measure and report Core Web Vitals\nGoogle believes that the Core Web Vitals are critical to all web experiences. As a result, it is committed to surfacing these metrics\nin all of its popular tools\n. The following sections details which tools support the Core Web Vitals.\nField tools to measure Core Web Vitals\nThe\nChrome User Experience Report\ncollects anonymized, real user measurement data for each Core Web Vital. This data enables site owners to quickly assess their performance without requiring them to manually instrument analytics on their pages, and powers tools like\nChrome DevTools\n,\nPageSpeed Insights\n, and Search Console's\nCore Web Vitals report\n.\nLCP\nINP\nCLS\nChrome User Experience Report\ncheck\ncheck\ncheck\nChrome DevTools\ncheck\ncheck\ncheck\nPageSpeed Insights\ncheck\ncheck\ncheck\nSearch Console (Core Web Vitals report)\ncheck\ncheck\ncheck\nThe data provided by Chrome User Experience Report offers a quick way to assess the performance of sites, but it does not provide the detailed, per-pageview telemetry that is often necessary to accurately diagnose, monitor, and quickly react to regressions. As a result, we strongly recommend that sites set up their own real-user monitoring.\nMeasure Core Web Vitals in JavaScript\nEach of the Core Web Vitals can be measured in JavaScript using standard web APIs.\nThe easiest way to measure all the Core Web Vitals is to use the\nweb-vitals\nJavaScript library, a small, production-ready wrapper around the underlying web APIs that measures each metric in a way that accurately matches how they're reported by all the Google tools listed earlier.\nWith the\nweb-vitals\nlibrary, measuring each metric can be done by calling a single function. See the documentation for complete\nusage\nand\nAPI\ndetails.\nimport\n{\nonCLS\n,\nonINP\n,\nonLCP\n}\nfrom\n'web-vitals'\n;\nfunction\nsendToAnalytics\n(\nmetric\n)\n{\nconst\nbody\n=\nJSON\n.\nstringify\n(\nmetric\n);\n// Use `navigator.sendBeacon()` if available, falling back to `fetch()`.\n(\nnavigator\n.\nsendBeacon\n&&\nnavigator\n.\nsendBeacon\n(\n'/analytics'\n,\nbody\n))\n||\nfetch\n(\n'/analytics'\n,\n{\nbody\n,\nmethod\n:\n'POST'\n,\nkeepalive\n:\ntrue\n});\n}\nonCLS\n(\nsendToAnalytics\n);\nonINP\n(\nsendToAnalytics\n);\nonLCP\n(\nsendToAnalytics\n);\nOnce you've configured your site to use the\nweb-vitals\nlibrary to measure and send your Core Web Vitals data to an analytics endpoint, the next step is to aggregate and report on that data to see if your pages are meeting the recommended thresholds for at least 75% of page visits.\nWhile some analytics providers have built-in support for Core Web Vitals metrics, even those that don't should include basic custom metric features that allow you to measure Core Web Vitals in their tool.\nDevelopers who prefer to measure these metrics directly using the underlying web APIs can instead use these metric guides for implementation details:\nMeasure LCP in JavaScript\nMeasure INP in JavaScript\nMeasure CLS in JavaScript\nFor additional guidance on measuring these metrics using popular analytics services or your own in-house analytics tools, see\nBest practices for measuring Web Vitals in the field\n.\nLab tools to measure Core Web Vitals\nWhile all of the Core Web Vitals are, first and foremost, field metrics, many of them are also measurable in the lab.\nLab measurement is the best way to test the performance of features during development\u2014before they've been released to users. It's also the best way to catch performance regressions before they happen.\nThe following tools can be used to measure the Core Web Vitals in a lab environment:\nLCP\nINP\nCLS\nChrome DevTools\ncheck\ncheck\ncheck\nLighthouse\ncheck\nblock\n(use\nTBT\ninstead)\ncheck\nWhile lab measurement is an essential part of delivering great experiences, it is not a substitute for field measurement.\nThe performance of a site can substantially vary based on a user's device capabilities, their network conditions, what other processes may be running on the device, and how they're interacting with the page. In fact, each of the Core Web Vitals metrics can have its score affected by user interaction. Only field measurement can accurately capture the complete picture.\nRecommendations for improving your scores\nThe following guides offer specific recommendations for how to optimize your pages for each of the Core Web Vitals:\nOptimize LCP\nOptimize INP\nOptimize CLS\nThere are many ways to improve Core Web Vitals, and each approach comes with varying levels of impact, relevance, and ease of use for every situation. Refer to\nThe most effective ways to improve Core Web Vitals\nfor a short list of the Chrome team's top recommendations.\nOther Web Vitals\nWhile the Core Web Vitals are the critical metrics for understanding and delivering a great user experience, there are other supporting metrics.\nThese other metrics can serve as proxy\u2014or as supplemental metrics for the three Core Web Vitals\u2014to help capture a larger part of the experience or to aid in diagnosing a specific issue.\nFor example, the metrics\nTime to First Byte (TTFB)\nand\nFirst Contentful Paint (FCP)\nare both vital aspects of the\nloading\nexperience, and are both useful in diagnosing issues with LCP (slow\nserver response times\nor\nrender-blocking resources\n, respectively).\nSimilarly, a metric like\nTotal Blocking Time (TBT)\nis a lab metrics is vital in catching and diagnosing potential\ninteractivity\nissues that can impact INP. However, it is not part of the Core Web Vitals set because they are not field-measurable, nor do they reflect a\nuser-centric\noutcome.\nChanges to Web Vitals\nWeb Vitals and Core Web Vitals represent the best available signals developers have today to measure quality of experience across the web, but these signals are not perfect and future improvements or additions should be expected.\nThe\nCore Web Vitals\nare relevant to all web pages and featured across relevant Google tools. Changes to these metrics will have wide-reaching impact; as such, developers should expect the definitions and thresholds of the Core Web Vitals to be stable, and updates to have prior notice and a predictable, annual cadence.\nThe other Web Vitals are often context or tool specific, and may be more experimental than the Core Web Vitals. As such, their definitions and thresholds may change with greater frequency.\nFor all Web Vitals, changes will be clearly documented in this public\nCHANGELOG\n.\nExcept as otherwise noted, the content of this page is licensed under the\nCreative Commons Attribution 4.0 License\n, and code samples are licensed under the\nApache 2.0 License\n. For details, see the\nGoogle Developers Site Policies\n. Java is a registered trademark of Oracle and/or its affiliates.\nLast updated 2024-10-31 UTC.",
  "content_markdown": "- [Home](https://web.dev/)\n- [Articles](https://web.dev/articles)\n\n# Web Vitals Stay organized with collections Save and categorize content based on your preferences.\n\n![Philip Walton](https://web.dev/images/authors/philipwalton.jpg)\n\nPhilip Walton\n\nPublished: May 4, 2020\n\nOptimizing for quality of user experience is key to the long-term success of any site on the web. Whether you're a business owner, marketer, or developer, Web Vitals can help you quantify the experience of your site and identify opportunities to improve.\n\n## Overview\n\nWeb Vitals is an initiative by Google to provide unified guidance for quality signals that are essential to delivering a great user experience on the web.\n\nGoogle has provided a number of tools over the years to measure and report on performance. Some developers are experts at using these tools, while others have found the abundance of both tools and metrics challenging to keep up with.\n\nSite owners shouldn't have to be performance experts to understand the quality of experience they are delivering to their users. The Web Vitals initiative aims to simplify the landscape, and help sites focus on the metrics that matter most, the **Core Web Vitals**.\n\n## Core Web Vitals\n\nCore Web Vitals are the subset of Web Vitals that apply to all web pages, should be measured by all site owners, and will be surfaced across all Google tools. Each of the Core Web Vitals represents a distinct facet of the user experience, is measurable [in the field](/articles/user-centric-performance-metrics#how_metrics_are_measured), and reflects the real-world experience of a critical [user-centric](/articles/user-centric-performance-metrics#how_metrics_are_measured) outcome.\n\nThe metrics that make up Core Web Vitals will [evolve](#evolving-web-vitals) over time. The current set focuses on three aspects of the user experience\u2014*loading*, *interactivity*, and *visual stability*\u2014and includes the following metrics (and their respective thresholds):\n\n![Largest Contentful Paint threshold recommendations](/static/articles/vitals/image/largest-contentful-paint-ea2e6ec5569b6.svg)\n![Interaction to Next Paint threshold recommendations](/static/articles/vitals/image/inp-thresholds.svg)\n![Cumulative Layout Shift threshold recommendations](/static/articles/vitals/image/cumulative-layout-shift-t-5d49b9b883de4.svg)\n\n- **[Largest Contentful Paint (LCP)](/articles/lcp)**: measures *loading* performance. To provide a good user experience, LCP should occur within **2.5 seconds** of when the page first starts loading.\n- **[Interaction to Next Paint (INP)](/articles/inp)**: measures *interactivity*. To provide a good user experience, pages should have a INP of **200 milliseconds** or less.\n- **[Cumulative Layout Shift (CLS)](/articles/cls)**: measures *visual stability*. To provide a good user experience, pages should maintain a CLS of **0.1.** or less.\n\nTo ensure you're hitting the recommended target for these metrics for most of your users, a good threshold to measure is the **75th percentile** of page loads, segmented across mobile and desktop devices.\n\nTools that assess Core Web Vitals compliance should consider a page passing if it meets the recommended targets at the 75th percentile for all three of the Core Web Vitals metrics.\n\n### Lifecycle\n\nMetrics on the Core Web Vitals track go through a lifecycle consisting of three phases: experimental, pending, and stable.\n\n![The three lifecycle phases of Core Web Vitals metrics, visualized as a series of three chevrons. From left to right, the phases are Experimental, Pending, and Stable.](/static/articles/vitals/image/the-three-lifecycle-phase-0d329be3158f9.svg)\n\nThe stages of the Core Web Vitals lifecycle.\n\nEach phase is designed to signal to developers how they should think about each metric:\n\n- **Experimental metrics** are prospective Core Web Vitals that may still be undergoing significant changes depending on testing and community feedback.\n- **Pending metrics** are future Core Web Vitals that have passed the testing and feedback stage and have a well-defined timeline to becoming stable.\n- **Stable metrics** are the current set of Core Web Vitals that Chrome considers essential for great user experiences.\n\nThe Core Web Vitals are at the following lifecycle stages:\n\n- [LCP](/articles/lcp): Stable\n- [CLS](/articles/cls): Stable\n- [INP](/articles/inp): Stable\n\n#### Experimental\n\nWhen a metric is initially developed and enters the ecosystem, it is considered an *experimental metric*.\n\nThe purpose of the experimental phase is to assess a metric's fitness, first by exploring the problem to be solved, and possibly iterate on what previous metrics may have failed to address. For example, [Interaction to Next Paint (INP)](/articles/inp) was initially developed as an experimental metric to address the runtime performance issues present on the web more comprehensively than [First Input Delay (FID)](/articles/fid).\n\nThe experimental phase of Core Web Vitals lifecycle is also intended to give flexibility in a metric's development by identifying bugs and even exploring changes to its initial definition. It's also the phase in which community feedback is most important.\n\n#### Pending\n\nWhen the Chrome team determines that an experimental metric has received sufficient feedback and proven its efficacy, it becomes a *pending metric*. For example, INP was promoted in 2023 from experimental to pending status with the intent to eventually retire FID.\n\nPending metrics are held in this phase for a minimum of six months to give the ecosystem time to adapt. Community feedback remains an important aspect of this phase, as more developers begin to use the metric.\n\n#### Stable\n\nWhen a Core Web Vital candidate metric is finalized, it becomes a *stable metric*. This is when the metric can become a Core Web Vital.\n\nStable metrics are actively supported, and can be subject to bug fixes and definition changes. Stable Core Web Vitals metrics won't change more than once per year. Any change to a Core Web Vital will be clearly communicated in the metric's official documentation, as well as in the metric's changelog. Core Web Vitals are also included in any assessments.\n\n### Tools to measure and report Core Web Vitals\n\nGoogle believes that the Core Web Vitals are critical to all web experiences. As a result, it is committed to surfacing these metrics [in all of its popular tools](/articles/vitals-tools). The following sections details which tools support the Core Web Vitals.\n\n#### Field tools to measure Core Web Vitals\n\nThe [Chrome User Experience Report](https://developer.chrome.com/docs/crux) collects anonymized, real user measurement data for each Core Web Vital. This data enables site owners to quickly assess their performance without requiring them to manually instrument analytics on their pages, and powers tools like [Chrome DevTools](https://developer.chrome.com/docs/devtools/performance/overview#compare), [PageSpeed Insights](https://pagespeed.web.dev), and Search Console's [Core Web Vitals report](https://support.google.com/webmasters/answer/9205520).\n\n|  |  |  |  |\n| --- | --- | --- | --- |\n|  | LCP | INP | CLS |\n| [Chrome User Experience Report](https://developer.chrome.com/docs/crux) | check | check | check |\n| [Chrome DevTools](https://developer.chrome.com/docs/devtools/performance/overview#compare) | check | check | check |\n| [PageSpeed Insights](https://developers.google.com/speed/pagespeed/insights/) | check | check | check |\n| [Search Console (Core Web Vitals report)](https://support.google.com/webmasters/answer/9205520) | check | check | check |\n\nThe data provided by Chrome User Experience Report offers a quick way to assess the performance of sites, but it does not provide the detailed, per-pageview telemetry that is often necessary to accurately diagnose, monitor, and quickly react to regressions. As a result, we strongly recommend that sites set up their own real-user monitoring.\n\n#### Measure Core Web Vitals in JavaScript\n\nEach of the Core Web Vitals can be measured in JavaScript using standard web APIs.\n\nThe easiest way to measure all the Core Web Vitals is to use the [web-vitals](https://github.com/GoogleChrome/web-vitals) JavaScript library, a small, production-ready wrapper around the underlying web APIs that measures each metric in a way that accurately matches how they're reported by all the Google tools listed earlier.\n\nWith the [web-vitals](https://github.com/GoogleChrome/web-vitals) library, measuring each metric can be done by calling a single function. See the documentation for complete [usage](https://github.com/GoogleChrome/web-vitals#usage) and [API](https://github.com/GoogleChrome/web-vitals#api) details.\n\n```\nimport {onCLS, onINP, onLCP} from 'web-vitals';\n\nfunction sendToAnalytics(metric) {\n  const body = JSON.stringify(metric);\n  // Use `navigator.sendBeacon()` if available, falling back to `fetch()`.\n  (navigator.sendBeacon && navigator.sendBeacon('/analytics', body)) ||\n    fetch('/analytics', {body, method: 'POST', keepalive: true});\n}\n\nonCLS(sendToAnalytics);\nonINP(sendToAnalytics);\nonLCP(sendToAnalytics);\n```\n\nOnce you've configured your site to use the [web-vitals](https://github.com/GoogleChrome/web-vitals) library to measure and send your Core Web Vitals data to an analytics endpoint, the next step is to aggregate and report on that data to see if your pages are meeting the recommended thresholds for at least 75% of page visits.\n\nWhile some analytics providers have built-in support for Core Web Vitals metrics, even those that don't should include basic custom metric features that allow you to measure Core Web Vitals in their tool.\n\nDevelopers who prefer to measure these metrics directly using the underlying web APIs can instead use these metric guides for implementation details:\n\n- [Measure LCP in JavaScript](/articles/lcp#measure_lcp_in_javascript)\n- [Measure INP in JavaScript](/articles/inp#how-to-measure-inp)\n- [Measure CLS in JavaScript](/articles/cls#measure_cls_in_javascript)\n\nFor additional guidance on measuring these metrics using popular analytics services or your own in-house analytics tools, see [Best practices for measuring Web Vitals in the field](/articles/vitals-field-measurement-best-practices).\n\n#### Lab tools to measure Core Web Vitals\n\nWhile all of the Core Web Vitals are, first and foremost, field metrics, many of them are also measurable in the lab.\n\nLab measurement is the best way to test the performance of features during development\u2014before they've been released to users. It's also the best way to catch performance regressions before they happen.\n\nThe following tools can be used to measure the Core Web Vitals in a lab environment:\n\n|  | LCP | INP | CLS |\n| --- | --- | --- | --- |\n| [Chrome DevTools](https://developer.chrome.com/docs/devtools) | check | check | check |\n| [Lighthouse](https://developer.chrome.com/docs/lighthouse/overview) | check | block (use [TBT](/articles/tbt) instead) | check |\n\nWhile lab measurement is an essential part of delivering great experiences, it is not a substitute for field measurement.\n\nThe performance of a site can substantially vary based on a user's device capabilities, their network conditions, what other processes may be running on the device, and how they're interacting with the page. In fact, each of the Core Web Vitals metrics can have its score affected by user interaction. Only field measurement can accurately capture the complete picture.\n\n### Recommendations for improving your scores\n\nThe following guides offer specific recommendations for how to optimize your pages for each of the Core Web Vitals:\n\n- [Optimize LCP](/articles/optimize-lcp)\n- [Optimize INP](/articles/optimize-inp)\n- [Optimize CLS](/articles/optimize-cls)\n\nThere are many ways to improve Core Web Vitals, and each approach comes with varying levels of impact, relevance, and ease of use for every situation. Refer to [The most effective ways to improve Core Web Vitals](/articles/top-cwv) for a short list of the Chrome team's top recommendations.\n\n## Other Web Vitals\n\nWhile the Core Web Vitals are the critical metrics for understanding and delivering a great user experience, there are other supporting metrics.\n\nThese other metrics can serve as proxy\u2014or as supplemental metrics for the three Core Web Vitals\u2014to help capture a larger part of the experience or to aid in diagnosing a specific issue.\n\nFor example, the metrics [Time to First Byte (TTFB)](/articles/ttfb) and [First Contentful Paint (FCP)](/articles/fcp) are both vital aspects of the *loading* experience, and are both useful in diagnosing issues with LCP (slow [server response times](/articles/overloaded-server) or [render-blocking resources](https://developer.chrome.com/docs/lighthouse/performance/render-blocking-resources), respectively).\n\nSimilarly, a metric like [Total Blocking Time (TBT)](/articles/tbt) is a lab metrics is vital in catching and diagnosing potential *interactivity* issues that can impact INP. However, it is not part of the Core Web Vitals set because they are not field-measurable, nor do they reflect a [user-centric](/articles/user-centric-performance-metrics#how_metrics_are_measured) outcome.\n\n## Changes to Web Vitals\n\nWeb Vitals and Core Web Vitals represent the best available signals developers have today to measure quality of experience across the web, but these signals are not perfect and future improvements or additions should be expected.\n\nThe **Core Web Vitals** are relevant to all web pages and featured across relevant Google tools. Changes to these metrics will have wide-reaching impact; as such, developers should expect the definitions and thresholds of the Core Web Vitals to be stable, and updates to have prior notice and a predictable, annual cadence.\n\nThe other Web Vitals are often context or tool specific, and may be more experimental than the Core Web Vitals. As such, their definitions and thresholds may change with greater frequency.\n\nFor all Web Vitals, changes will be clearly documented in this public [CHANGELOG](https://chromium.googlesource.com/chromium/src/+/main/docs/speed/metrics_changelog/README.md).\n\nExcept as otherwise noted, the content of this page is licensed under the [Creative Commons Attribution 4.0 License](https://creativecommons.org/licenses/by/4.0/), and code samples are licensed under the [Apache 2.0 License](https://www.apache.org/licenses/LICENSE-2.0). For details, see the [Google Developers Site Policies](https://developers.google.com/site-policies). Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2024-10-31 UTC.\n\n[[[\"Easy to understand\",\"easyToUnderstand\",\"thumb-up\"],[\"Solved my problem\",\"solvedMyProblem\",\"thumb-up\"],[\"Other\",\"otherUp\",\"thumb-up\"]],[[\"Missing the information I need\",\"missingTheInformationINeed\",\"thumb-down\"],[\"Too complicated / too many steps\",\"tooComplicatedTooManySteps\",\"thumb-down\"],[\"Out of date\",\"outOfDate\",\"thumb-down\"],[\"Samples / code issue\",\"samplesCodeIssue\",\"thumb-down\"],[\"Other\",\"otherDown\",\"thumb-down\"]],[\"Last updated 2024-10-31 UTC.\"],[],[]]",
  "tags": [
    "performance",
    "web-vitals",
    "google",
    "optimization"
  ],
  "extracted_at": "2026-02-03T12:49:09.014461+00:00",
  "content_length": 11683,
  "content_hash": "9cb7673df6b1d5f0"
}