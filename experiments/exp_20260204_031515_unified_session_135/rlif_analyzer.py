import os
import json
from typing import Dict

# Placeholder for a heavier model call.
# In a real deployment this would invoke a LLM (e.g., OpenAI GPT) with a system prompt.
def _heavy_model_analyze(context: str) -> str:
    # This stub simply returns a generic analysis.
    # Replace with actual LLM call when available.
    return "The system failed to validate the existence of the target directory before attempting to delete it."

def analyze_issue(user_input: str, system_output: str, context: str = "") -> str:
    """
    Analyzes why a negative sentiment occurred.
    Parameters
    ----------
    user_input : str
        The original request from the user.
    system_output : str
        The response generated by the system.
    context : str, optional
        Additional context (e.g., logs, stack traces).

    Returns
    -------
    str
        A concise rootâ€‘cause description.
    """
    # Build a short prompt for the heavy model.
    prompt = (
        f"User request: {user_input}\n"
        f"System response: {system_output}\n"
        f"Additional context: {context}\n"
        "Explain in one sentence what went wrong and why the user is frustrated."
    )
    # In production replace this with a call to the LLM.
    analysis = _heavy_model_analyze(prompt)
    return analysis.strip()