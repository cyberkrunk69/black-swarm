{"complexity": "complex", "subtasks": [{"id": 1, "assigned_to": "CODER", "description": "Enumerate all sub\u2011directories inside `experiments/` and filter those whose last\u2011modified timestamp is older than 24\u202fhours (exclude any directory modified today). Produce a JSON list `old_experiments.json` containing the full paths of these directories.", "acceptance_criteria": "A file `old_experiments.json` exists at the repository root. It contains an array of absolute or relative paths, each pointing to an experiment directory older than 24\u202fh. No directories from the current day are included."}, {"id": 2, "assigned_to": "CODER", "description": "For each directory listed in `old_experiments.json`, inspect its contents to determine if it holds useful output:\n- Consider a directory useful if it contains at least one non\u2011empty file whose content is not an exact duplicate of a file in another directory.\n- Generate two JSON files: `useful_experiments.json` (paths to directories to keep) and `duplicate_or_empty_experiments.json` (paths to directories to delete). Also create a CSV `duplicate_report.csv` summarizing duplicate file groups (original path, duplicate path, size).", "acceptance_criteria": "Both JSON files are present and correctly partition the old experiments. `duplicate_report.csv` lists each set of duplicate files with their sizes. No directory from today appears in either list."}, {"id": 3, "assigned_to": "CODER", "description": "Delete all directories listed in `duplicate_or_empty_experiments.json`. After deletion, compute the total number of directories removed, the number retained, and the total bytes freed. Write these statistics to `prune_summary.txt` in the format:\n```\nDeleted: X directories\nKept: Y directories\nBytes freed: Z bytes\n```", "acceptance_criteria": "`prune_summary.txt` exists and reports accurate numbers matching the filesystem state after deletion. All directories slated for removal are no longer present; all directories in `useful_experiments.json` remain intact."}, {"id": 4, "assigned_to": "CODER", "description": "Create a short README section (`PRUNE_GUIDE.md`) that documents the pruning process, explains how the generated JSON/CSV files are structured, and provides instructions for re\u2011running the script safely.", "acceptance_criteria": "`PRUNE_GUIDE.md` is added to the repo, is markdown\u2011formatted, and clearly describes the steps, file outputs, and safety precautions (e.g., never run on today\u2019s data)."}], "next_role": "CODER", "critic_review": {"score": 1.0, "issues": [], "feedback": ["[OK] Code quality looks good!"], "passed": true, "timestamp": "2026-02-03T20:20:04.573467", "context": {"filename": "/app/grind_logs/session_1_run_157.json", "task": "PRUNE: experiments/ directory\n\nThere are 1824 experiment directories, most are garbage duplicates.\n\n1. List all experiments older than 24 hours\n2. Check which ones have actual useful output (non-empty, non-duplicate files)\n3. Delete empty or duplicate experiment directories\n4. Keep only experiments with unique, substantial output\n5. Report: X deleted, Y kept, Z bytes freed\n\nBE CAREFUL - don't delete anything from today.", "session_id": 1, "run": 157}}, "quality_score": 1.0, "critic_feedback": ["[OK] Code quality looks good!"], "critic_retry_count": 0}