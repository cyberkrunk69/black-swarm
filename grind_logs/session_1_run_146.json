{"complexity": "complex", "subtasks": [{"id": 1, "assigned_to": "CODER", "description": "Traverse the `experiments/` directory and list all experiment sub\u2011directories whose last\u2011modified timestamp is older than 24\u202fhours. Produce a machine\u2011readable list (e.g., JSON or CSV) containing each directory path, its total size in bytes, and its modification time.", "acceptance_criteria": "A file `experiment_list.json` is created containing an array of objects with fields `path`, `size_bytes`, and `mtime`. All entries are strictly older than 24\u202fhours; no directory from the current day appears."}, {"id": 2, "assigned_to": "CODER", "description": "For each directory from the list, inspect its contents to decide if it holds useful output. Useful output is defined as at least one non\u2011empty file that is not an exact duplicate of a file in another experiment directory. Compute a hash (e.g., SHA\u2011256) for every file to detect duplicates across experiments. Produce two lists: `keep_dirs` (unique, substantial output) and `delete_dirs` (empty or duplicate\u2011only).", "acceptance_criteria": "Two files are generated: `keep_dirs.json` and `delete_dirs.json`. `keep_dirs.json` contains paths of directories with at least one non\u2011empty, non\u2011duplicate file. `delete_dirs.json` contains paths of directories that are either completely empty or contain only files whose hashes appear in another directory."}, {"id": 3, "assigned_to": "CODER", "description": "Safely delete every directory listed in `delete_dirs.json`. Perform the deletions atomically (e.g., using `shutil.rmtree`) and log each deletion. Ensure that no directory whose modification time is within the current day is touched, even if it mistakenly appears in the list.", "acceptance_criteria": "All directories in `delete_dirs.json` are removed from the filesystem. A log file `deletion_log.txt` records each deleted path and any errors. A sanity check confirms that no directory with `mtime` within the last 24\u202fhours remains deleted."}, {"id": 4, "assigned_to": "CODER", "description": "Generate a final report summarizing the pruning operation: number of directories deleted (X), number kept (Y), and total bytes freed (Z). Write the report to `prune_report.txt` and also output the same information to stdout.", "acceptance_criteria": "`prune_report.txt` contains three lines (or a clear table) reporting X deleted, Y kept, and Z bytes freed. The same numbers are printed to the console when the script finishes."}], "next_role": "CODER", "critic_review": {"score": 1.0, "issues": [], "feedback": ["[OK] Code quality looks good!"], "passed": true, "timestamp": "2026-02-03T20:19:08.713081", "context": {"filename": "/app/grind_logs/session_1_run_146.json", "task": "PRUNE: experiments/ directory\n\nThere are 1824 experiment directories, most are garbage duplicates.\n\n1. List all experiments older than 24 hours\n2. Check which ones have actual useful output (non-empty, non-duplicate files)\n3. Delete empty or duplicate experiment directories\n4. Keep only experiments with unique, substantial output\n5. Report: X deleted, Y kept, Z bytes freed\n\nBE CAREFUL - don't delete anything from today.", "session_id": 1, "run": 146}}, "quality_score": 1.0, "critic_feedback": ["[OK] Code quality looks good!"], "critic_retry_count": 0}