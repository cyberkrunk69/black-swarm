{"complexity": "complex", "subtasks": [{"id": 1, "assigned_to": "CODER", "description": "Traverse the `experiments/` directory and produce a list of all experiment sub\u2011directories whose last\u2011modified timestamp is older than 24\u202fhours. Exclude any directory whose modification date is within the last 24\u202fhours (i.e., today). Output the list to a temporary JSON file `old_experiments.json` with each entry containing the absolute path and the modification timestamp.", "acceptance_criteria": "A JSON file `old_experiments.json` exists and contains only experiment directories older than 24\u202fhours, with correct absolute paths and timestamps. No directory from the last 24\u202fhours is present."}, {"id": 2, "assigned_to": "CODER", "description": "For each directory listed in `old_experiments.json`, inspect its contents to decide if it holds useful output. Useful output is defined as any non\u2011empty file that is not an exact duplicate of a file in another experiment directory. Compute a SHA\u2011256 hash for every file, build a map of hash \u2192 list of file paths, and flag directories that contain only empty files or files whose hashes appear in more than one directory (duplicates). Produce two JSON files: `to_keep.json` (directories with unique, non\u2011empty files) and `to_delete.json` (directories that are empty or contain only duplicate files).", "acceptance_criteria": "`to_keep.json` and `to_delete.json` are created. Every directory in `to_keep.json` contains at least one non\u2011empty file with a unique hash across all experiments. Every directory in `to_delete.json` contains only empty files or files whose hashes are duplicated in another experiment directory. No directory from the last 24\u202fhours appears in either file."}, {"id": 3, "assigned_to": "CODER", "description": "Delete all directories listed in `to_delete.json` safely. Before deletion, log each path to `deleted_experiments.log`. After removal, compute the total freed disk space (sum of sizes of all deleted files) and store the value in a variable for the final report.", "acceptance_criteria": "All directories in `to_delete.json` are removed from the filesystem. `deleted_experiments.log` contains a line for each deleted directory. The variable `bytes_freed` correctly reflects the total size of files removed."}, {"id": 4, "assigned_to": "CODER", "description": "Generate a concise report printed to STDOUT (and saved as `prune_report.txt`) summarizing: the number of directories deleted, the number kept, and the total bytes freed (human\u2011readable format). Ensure the report matches the data collected in previous steps.", "acceptance_criteria": "`prune_report.txt` exists and contains a clear summary like: \"Deleted: X directories, Kept: Y directories, Freed: Z bytes (Z\u202fMiB).\" The numbers X, Y, and Z correspond exactly to the counts and size computed in steps 2 and 3."}], "next_role": "CODER", "critic_review": {"score": 1.0, "issues": [], "feedback": ["[OK] Code quality looks good!"], "passed": true, "timestamp": "2026-02-03T20:15:26.450759", "context": {"filename": "/app/grind_logs/session_1_run_104.json", "task": "PRUNE: experiments/ directory\n\nThere are 1824 experiment directories, most are garbage duplicates.\n\n1. List all experiments older than 24 hours\n2. Check which ones have actual useful output (non-empty, non-duplicate files)\n3. Delete empty or duplicate experiment directories\n4. Keep only experiments with unique, substantial output\n5. Report: X deleted, Y kept, Z bytes freed\n\nBE CAREFUL - don't delete anything from today.", "session_id": 1, "run": 104}}, "quality_score": 1.0, "critic_feedback": ["[OK] Code quality looks good!"], "critic_retry_count": 0}