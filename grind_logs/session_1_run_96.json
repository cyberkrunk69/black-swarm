{"complexity": "complex", "subtasks": [{"id": 1, "assigned_to": "CODER", "description": "Scan the `experiments/` directory and generate a JSON/CSV file listing every experiment sub\u2011directory that is older than 24\u202fhours. Include for each entry: path, last\u2011modified timestamp, total size in bytes, and a flag indicating if the directory is from today (to be excluded from any later deletion).", "acceptance_criteria": "A file `experiment_scan.json` is created containing an array of objects with the required fields. No directories are modified or deleted in this step. The list correctly excludes any directory whose last\u2011modified timestamp is within the last 24\u202fhours."}, {"id": 2, "assigned_to": "CODER", "description": "Analyze each directory from the scan to determine if it contains useful output. A directory is considered useful if it has at least one non\u2011empty file that is not an exact duplicate of a file in another directory (use a SHA\u2011256 hash of file contents to detect duplicates). Produce a second file `experiment_analysis.json` marking each directory as `keep` or `delete` based on: (a) empty or only duplicate files \u2192 delete, (b) contains unique substantive files \u2192 keep.", "acceptance_criteria": "`experiment_analysis.json` lists every scanned directory with a boolean `keep` field. Directories from today are always marked `keep`. Duplicate detection correctly groups identical files across directories, and any directory whose all files are duplicates or empty is marked `delete`."}, {"id": 3, "assigned_to": "CODER", "description": "Delete all directories flagged as `delete` in `experiment_analysis.json`. Ensure the deletion is safe: double\u2011check the directory is not from today and that it is empty after removal of duplicate files. Log each deletion to `prune_log.txt` with timestamp, path, and size freed.", "acceptance_criteria": "All directories marked `delete` are removed from the filesystem. No directory from today is touched. `prune_log.txt` contains one line per deletion with accurate size reclaimed. The script exits without error."}, {"id": 4, "assigned_to": "CODER", "description": "After deletions, compute a final report summarizing: total number of directories deleted (X), total number kept (Y), and total bytes freed (Z). Write this summary to `prune_report.txt` and also print it to stdout.", "acceptance_criteria": "`prune_report.txt` exists and contains a clear one\u2011line summary like `Deleted: X directories, Kept: Y directories, Freed: Z bytes`. The numbers match the actual filesystem state after the script runs."}], "next_role": "CODER", "critic_review": {"score": 1.0, "issues": [], "feedback": ["[OK] Code quality looks good!"], "passed": true, "timestamp": "2026-02-03T20:14:42.967080", "context": {"filename": "/app/grind_logs/session_1_run_96.json", "task": "PRUNE: experiments/ directory\n\nThere are 1824 experiment directories, most are garbage duplicates.\n\n1. List all experiments older than 24 hours\n2. Check which ones have actual useful output (non-empty, non-duplicate files)\n3. Delete empty or duplicate experiment directories\n4. Keep only experiments with unique, substantial output\n5. Report: X deleted, Y kept, Z bytes freed\n\nBE CAREFUL - don't delete anything from today.", "session_id": 1, "run": 96}}, "quality_score": 1.0, "critic_feedback": ["[OK] Code quality looks good!"], "critic_retry_count": 0}