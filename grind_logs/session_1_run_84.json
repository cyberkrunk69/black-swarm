{"complexity": "complex", "subtasks": [{"id": 1, "assigned_to": "CODER", "description": "Scan the `experiments/` directory and produce a list of all experiment sub\u2011directories whose last\u2011modified timestamp is older than 24\u202fhours. Output the list to a temporary file `old_experiments.txt` (one path per line).", "acceptance_criteria": "The script creates `old_experiments.txt` containing only paths older than 24\u202fh and never includes directories modified within the last 24\u202fh (including today). The list size matches the expected number of old experiments."}, {"id": 2, "assigned_to": "CODER", "description": "For each directory in `old_experiments.txt`, evaluate whether it contains any useful output:\n- At least one non\u2011empty file, **and**\n- Its file contents are not exact duplicates of another old experiment (use a hash of all files in the directory to detect duplicates). Produce two new files: `keep_experiments.txt` (paths to retain) and `delete_experiments.txt` (paths to remove).", "acceptance_criteria": "`keep_experiments.txt` contains only directories with unique, non\u2011empty output. `delete_experiments.txt` contains directories that are empty or are exact duplicates of another kept directory. No directory from today appears in either file."}, {"id": 3, "assigned_to": "CODER", "description": "Delete all directories listed in `delete_experiments.txt`. While deleting, accumulate the total number of directories removed and the total number of bytes freed. After deletion, write a concise report to `prune_report.txt` with the format:\n```\nDeleted: <X> directories\nKept: <Y> directories\nBytes freed: <Z> bytes\n```\nEnsure the operation is safe (e.g., use `shutil.rmtree` with error handling) and does not touch any directory modified within the last 24\u202fhours.", "acceptance_criteria": "`prune_report.txt` exists and accurately reflects the number of directories deleted, kept, and the total bytes reclaimed. Running the script a second time results in zero deletions (idempotent) and the same report values for kept directories."}, {"id": 4, "assigned_to": "CODER", "description": "Wrap the above steps into a single executable Python script `prune_experiments.py` with a clear `if __name__ == \"__main__\":` entry point. The script should accept an optional path argument (default `./experiments`) and print the report to stdout after writing `prune_report.txt`.", "acceptance_criteria": "Running `python prune_experiments.py` (or with a custom path) executes all steps, prints the report, creates/updates the three text files, and exits with status code 0. The script includes docstrings, type hints, and minimal logging for progress."}], "next_role": "CODER", "critic_review": {"score": 1.0, "issues": [], "feedback": ["[OK] Code quality looks good!"], "passed": true, "timestamp": "2026-02-03T20:13:42.170131", "context": {"filename": "/app/grind_logs/session_1_run_84.json", "task": "PRUNE: experiments/ directory\n\nThere are 1824 experiment directories, most are garbage duplicates.\n\n1. List all experiments older than 24 hours\n2. Check which ones have actual useful output (non-empty, non-duplicate files)\n3. Delete empty or duplicate experiment directories\n4. Keep only experiments with unique, substantial output\n5. Report: X deleted, Y kept, Z bytes freed\n\nBE CAREFUL - don't delete anything from today.", "session_id": 1, "run": 84}}, "quality_score": 1.0, "critic_feedback": ["[OK] Code quality looks good!"], "critic_retry_count": 0}