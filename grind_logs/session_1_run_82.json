{"complexity": "complex", "subtasks": [{"id": 1, "assigned_to": "CODER", "description": "Scan the `experiments/` directory and produce a JSON/CSV file `old_experiments.json` listing all experiment sub\u2011directories whose modification time is older than 24\u202fhours. Do **not** include any directories created today.", "acceptance_criteria": "A file `old_experiments.json` exists and contains a list of absolute paths (or relative to `experiments/`) for every experiment older than 24\u202fh. The list size matches a manual `find` verification."}, {"id": 2, "assigned_to": "CODER", "description": "For each path in `old_experiments.json`, examine its contents and mark the experiment as **useful** if it contains at least one non\u2011empty file that is not an exact duplicate of a file in any other experiment. Produce a second file `useful_experiments.json` with the paths of experiments that satisfy this criteria.", "acceptance_criteria": "`useful_experiments.json` lists only experiments that have non\u2011empty, non\u2011duplicate output. A checksum (e.g., SHA\u2011256) comparison is used to detect duplicates. The file is well\u2011formed JSON."}, {"id": 3, "assigned_to": "CODER", "description": "Delete every experiment directory listed in `old_experiments.json` that is **not** present in `useful_experiments.json` (i.e., empty or duplicate experiments). Ensure no directory from today is touched. Record the total number of directories deleted and the total bytes freed.", "acceptance_criteria": "All unwanted experiment directories are removed from the filesystem. A log file `prune_summary.log` contains fields: `deleted_count`, `kept_count`, `bytes_freed`. Running `du -sh experiments/` after the operation shows the expected space reduction."}, {"id": 4, "assigned_to": "CODER", "description": "Create a short human\u2011readable report `prune_report.txt` summarising the operation: number of experiments deleted, number kept, and total bytes freed. Include a timestamp of when the pruning ran.", "acceptance_criteria": "`prune_report.txt` exists, is under 200\u202fwords, and accurately reflects the numbers from `prune_summary.log`. The timestamp format is ISO\u20118601."}], "next_role": "CODER", "critic_review": {"score": 1.0, "issues": [], "feedback": ["[OK] Code quality looks good!"], "passed": true, "timestamp": "2026-02-03T20:13:30.377062", "context": {"filename": "/app/grind_logs/session_1_run_82.json", "task": "PRUNE: experiments/ directory\n\nThere are 1824 experiment directories, most are garbage duplicates.\n\n1. List all experiments older than 24 hours\n2. Check which ones have actual useful output (non-empty, non-duplicate files)\n3. Delete empty or duplicate experiment directories\n4. Keep only experiments with unique, substantial output\n5. Report: X deleted, Y kept, Z bytes freed\n\nBE CAREFUL - don't delete anything from today.", "session_id": 1, "run": 82}}, "quality_score": 1.0, "critic_feedback": ["[OK] Code quality looks good!"], "critic_retry_count": 0}