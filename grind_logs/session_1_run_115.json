{"complexity": "complex", "subtasks": [{"id": 1, "assigned_to": "CODER", "description": "Create a Python script `prune_experiments.py` that scans the `experiments/` directory, lists all experiment sub\u2011directories older than 24\u202fhours, and records their paths, modification times, and total size.", "acceptance_criteria": "The script prints a JSON array of objects `{path, mtime, size}` for each qualifying directory. It must NOT include any directory whose modification time is within the last 24\u202fhours."}, {"id": 2, "assigned_to": "CODER", "description": "Extend the script to detect \"useful\" output: a directory is considered useful if it contains at least one non\u2011empty file that is not an exact duplicate of a file in another directory (use file size and SHA\u2011256 hash for duplicate detection).", "acceptance_criteria": "The script adds a boolean `useful` field to each entry. Duplicate detection must correctly mark directories whose only files are exact copies of files found elsewhere as not useful."}, {"id": 3, "assigned_to": "CODER", "description": "Implement the deletion logic: remove all directories older than 24\u202fhours that are not marked as useful (i.e., empty or only duplicate files). After deletion, compute and print a summary report: number of directories deleted, number kept, and total bytes freed.", "acceptance_criteria": "The script safely deletes only the intended directories, never touching any directory modified within the last 24\u202fhours. The final printed report matches the actual filesystem state (deleted count, kept count, bytes freed)."}, {"id": 4, "assigned_to": "CODER", "description": "Add a `--dry-run` flag to the script that performs all checks and prints the would\u2011be report without actually deleting anything.", "acceptance_criteria": "When invoked with `--dry-run`, the script outputs the same summary as a normal run but makes no changes to the filesystem."}, {"id": 5, "assigned_to": "CODER", "description": "Write a short README section at the top of the script explaining usage, safety precautions, and how the duplicate detection works.", "acceptance_criteria": "The README is clear, concise, and includes example commands for dry\u2011run and actual execution."}], "next_role": "CODER", "critic_review": {"score": 1.0, "issues": [], "feedback": ["[OK] Code quality looks good!"], "passed": true, "timestamp": "2026-02-03T20:16:25.798820", "context": {"filename": "/app/grind_logs/session_1_run_115.json", "task": "PRUNE: experiments/ directory\n\nThere are 1824 experiment directories, most are garbage duplicates.\n\n1. List all experiments older than 24 hours\n2. Check which ones have actual useful output (non-empty, non-duplicate files)\n3. Delete empty or duplicate experiment directories\n4. Keep only experiments with unique, substantial output\n5. Report: X deleted, Y kept, Z bytes freed\n\nBE CAREFUL - don't delete anything from today.", "session_id": 1, "run": 115}}, "quality_score": 1.0, "critic_feedback": ["[OK] Code quality looks good!"], "critic_retry_count": 0}