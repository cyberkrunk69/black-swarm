{"complexity": "complex", "subtasks": [{"id": 1, "assigned_to": "CODER", "description": "Write a Python script `prune_experiments.py` that scans the `experiments/` directory, lists all experiment sub\u2011directories older than 24\u202fhours, and records their paths and modification timestamps.", "acceptance_criteria": "The script prints a JSON array of objects `{ \"path\": <str>, \"mtime\": <ISO\u20118601> }` for every directory whose last\u2011modified time is >24\u202fh ago. No directories from the current day are included."}, {"id": 2, "assigned_to": "CODER", "description": "Extend the script to evaluate each candidate directory for \"useful output\":\n- Consider a directory useful if it contains at least one non\u2011empty file.\n- Compute SHA\u2011256 hashes of all files in a directory; if the set of hashes matches another directory, mark both as duplicates.\n- Produce three lists: `useful`, `empty`, and `duplicate` (the latter containing only the directories that should be removed, keeping one representative of each duplicate set).", "acceptance_criteria": "Running the script with `--dry-run` prints counts and paths for each list. The duplicate detection must be content\u2011based (hash comparison) and must not rely on directory names."}, {"id": 3, "assigned_to": "CODER", "description": "Add deletion logic to the script (executed only when the `--apply` flag is supplied). The script should:\n- Safely delete directories in the `empty` and `duplicate` lists.\n- Ensure no directory modified today is ever deleted.\n- Accumulate total bytes freed.\n- After deletion, output a final report: `X deleted, Y kept, Z bytes freed`.\n- Include a `--dry-run` mode that performs no deletions but shows the same report.", "acceptance_criteria": "When run with `--apply`, the script removes only the intended directories, never touching today\u2019s experiments. The final printed report matches the actual filesystem changes (deleted count and freed bytes). A `--dry-run` execution leaves the filesystem untouched and still prints the correct report."}, {"id": 4, "assigned_to": "CODER", "description": "Create a small README `prune_experiments.md` that explains how to use the script, the meaning of each flag, safety precautions, and how the duplicate detection works.", "acceptance_criteria": "README is present in the repository root, clearly outlines usage examples (`--dry-run`, `--apply`), and warns users not to run `--apply` without reviewing the dry\u2011run output."}], "next_role": "CODER", "critic_review": {"score": 1.0, "issues": [], "feedback": ["[OK] Code quality looks good!"], "passed": true, "timestamp": "2026-02-03T20:18:52.378381", "context": {"filename": "/app/grind_logs/session_1_run_143.json", "task": "PRUNE: experiments/ directory\n\nThere are 1824 experiment directories, most are garbage duplicates.\n\n1. List all experiments older than 24 hours\n2. Check which ones have actual useful output (non-empty, non-duplicate files)\n3. Delete empty or duplicate experiment directories\n4. Keep only experiments with unique, substantial output\n5. Report: X deleted, Y kept, Z bytes freed\n\nBE CAREFUL - don't delete anything from today.", "session_id": 1, "run": 143}}, "quality_score": 1.0, "critic_feedback": ["[OK] Code quality looks good!"], "critic_retry_count": 0}