{"complexity": "complex", "subtasks": [{"id": 1, "assigned_to": "CODER", "description": "Traverse the `experiments/` directory and produce a list (e.g., JSON or CSV) of all experiment sub\u2011directories whose last\u2011modified timestamp is older than 24\u202fhours. Exclude any directory modified today.", "acceptance_criteria": "A file `old_experiments.json` is created at the project root containing an array of absolute paths for all qualifying experiment directories. The list is reproducible and matches a manual `find` command (`find experiments -type d -mtime +0`)."}, {"id": 2, "assigned_to": "CODER", "description": "For each directory in `old_experiments.json`, inspect its contents to decide if the experiment has useful output. Useful output is defined as at least one non\u2011empty file that is not an exact duplicate of a file in any other experiment directory. Produce a second file `useful_experiments.json` containing only the paths of directories deemed useful.", "acceptance_criteria": "`useful_experiments.json` lists directories that contain at least one file with size > 0 bytes and whose hash (e.g., SHA\u2011256) is unique across all examined experiments. A log `duplicate_check.log` records any duplicate files found and the directories they belong to."}, {"id": 3, "assigned_to": "CODER", "description": "Delete all experiment directories that appear in `old_experiments.json` but NOT in `useful_experiments.json`. Ensure the deletion is safe (e.g., use `shutil.rmtree` with error handling) and that no directory from today is touched.", "acceptance_criteria": "All unwanted directories are removed from the filesystem. The script prints a summary of deletions and writes `deletion_report.json` containing arrays `deleted` and `kept` with absolute paths."}, {"id": 4, "assigned_to": "CODER", "description": "Calculate the total disk space reclaimed by the deletions and produce a final human\u2011readable report indicating: number of directories deleted, number kept, and total bytes freed.", "acceptance_criteria": "The script outputs to STDOUT and writes `final_report.txt` with lines such as `Deleted: X directories, Kept: Y directories, Freed: Z bytes`. The byte count matches the sum of file sizes removed (verified via `du`)."}], "next_role": "CODER", "critic_review": {"score": 1.0, "issues": [], "feedback": ["[OK] Code quality looks good!"], "passed": true, "timestamp": "2026-02-03T20:15:53.253182", "context": {"filename": "/app/grind_logs/session_1_run_109.json", "task": "PRUNE: experiments/ directory\n\nThere are 1824 experiment directories, most are garbage duplicates.\n\n1. List all experiments older than 24 hours\n2. Check which ones have actual useful output (non-empty, non-duplicate files)\n3. Delete empty or duplicate experiment directories\n4. Keep only experiments with unique, substantial output\n5. Report: X deleted, Y kept, Z bytes freed\n\nBE CAREFUL - don't delete anything from today.", "session_id": 1, "run": 109}}, "quality_score": 1.0, "critic_feedback": ["[OK] Code quality looks good!"], "critic_retry_count": 0}