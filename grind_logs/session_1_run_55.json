{"complexity": "complex", "subtasks": [{"id": 1, "assigned_to": "CODER", "description": "Scan the `experiments/` directory and produce a list of all experiment sub\u2011directories whose last\u2011modified timestamp is older than 24\u202fhours. Output the list to a temporary JSON file (e.g., `old_experiments.json`).", "acceptance_criteria": "A JSON file containing the absolute paths of every experiment directory older than 24\u202fh is created. No directories from the current day are included."}, {"id": 2, "assigned_to": "CODER", "description": "For each directory from step\u202f1, inspect its contents and compute a content fingerprint (e.g., SHA\u2011256 hash of concatenated file hashes). Identify directories that are empty or whose fingerprint matches another directory (duplicate). Produce two lists: `to_delete.json` (empty or duplicate dirs) and `to_keep.json` (unique, non\u2011empty dirs).", "acceptance_criteria": "`to_delete.json` contains only paths that are either empty or exact duplicates of another directory. `to_keep.json` contains the remaining unique directories. No path from today appears in either list."}, {"id": 3, "assigned_to": "CODER", "description": "Safely delete all directories listed in `to_delete.json`. Before deletion, log each path and its size. Accumulate total freed bytes.", "acceptance_criteria": "All directories in `to_delete.json` are removed from the filesystem. A log file (`deletion_log.txt`) records each deleted path and its size, and the script reports the total bytes freed."}, {"id": 4, "assigned_to": "CODER", "description": "Generate a concise report summarizing the pruning operation: number of directories deleted (X), number kept (Y), and total bytes freed (Z). Write the report to `prune_report.txt`.", "acceptance_criteria": "`prune_report.txt` contains three lines with the exact numbers X, Y, and Z matching the actions performed in steps\u202f2\u20113."}, {"id": 5, "assigned_to": "CODER", "description": "Create a small wrapper script (`prune_experiments.py`) that ties together steps\u202f1\u20114, can be run safely, and includes a `--dry-run` flag to preview deletions without performing them.", "acceptance_criteria": "Running `python prune_experiments.py --dry-run` prints the lists of directories that would be deleted and the projected bytes to free, without modifying the filesystem. Running without `--dry-run` performs the full operation and produces the log and report files."}], "next_role": "CODER", "critic_review": {"score": 1.0, "issues": [], "feedback": ["[OK] Code quality looks good!"], "passed": true, "timestamp": "2026-02-03T20:11:08.367576", "context": {"filename": "/app/grind_logs/session_1_run_55.json", "task": "PRUNE: experiments/ directory\n\nThere are 1824 experiment directories, most are garbage duplicates.\n\n1. List all experiments older than 24 hours\n2. Check which ones have actual useful output (non-empty, non-duplicate files)\n3. Delete empty or duplicate experiment directories\n4. Keep only experiments with unique, substantial output\n5. Report: X deleted, Y kept, Z bytes freed\n\nBE CAREFUL - don't delete anything from today.", "session_id": 1, "run": 55}}, "quality_score": 1.0, "critic_feedback": ["[OK] Code quality looks good!"], "critic_retry_count": 0}